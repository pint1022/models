{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimising a TensorFlow SavedModel for Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebooks shows how to optimise the TensorFlow exported SavedModel by **shrinking** its size (to have less memory and disk footprints), and **improving** prediction latency. This can be accopmlished by applying the following:\n",
    "* **Freezing**: That is, converting the variables stored in a checkpoint file of the SavedModel into constants stored directly in the model graph.\n",
    "* **Pruning**: That is, stripping unused nodes during the prediction path of the graph, merging duplicate nodes, as well as removing other node ops like summary, identity, etc.\n",
    "* **Quantisation**:  That is, converting any large float Const op into an eight-bit equivalent, followed by a float conversion op so that the result is usable by subsequent nodes.\n",
    "* **Other refinements**: That includes constant folding, batch_norm folding, fusing convolusion, etc.\n",
    "\n",
    "The optimisation operations we apply in this example are from the TensorFlow [Graph Conversion Tool](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#fold_constants), which is a c++ command-line tool. We use the Python APIs to call the c++ libraries. \n",
    "\n",
    "The Graph Transform Tool is designed to work on models that are saved as GraphDef files, usually in a binary protobuf format. However, the model exported after training and estimator is in SavedModel format (saved_model.pb file + variables folder with variables.data-* and variables.index files). \n",
    "\n",
    "We need to optimise the mode and keep it the SavedModel format. Thus, the optimisation steps will be:\n",
    "1. Freeze the SavedModel: SavedModel -> GraphDef\n",
    "2. Optimisae the freezed model: GraphDef -> GraphDef\n",
    "3. Convert the optimised freezed model to SavedModel: GraphDef -> SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow : 1.13.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from absl import flags\n",
    "import tarfile\n",
    "\n",
    "from six.moves import urllib\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from official.utils.flags import core as flags_core\n",
    "from official.utils.logs import hooks_helper\n",
    "from official.resnet import resnet_model\n",
    "from official.resnet import resnet_run_loop\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "print (\"TensorFlow : {}\".format(tf.__version__))\n",
    "\n",
    "#tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train and Export a TensorFlow DNNClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\\resnet\\dnn\n"
     ]
    }
   ],
   "source": [
    "MODELS_LOCATION = 'models\\\\resnet'\n",
    "MODEL_NAME = 'dnn'\n",
    "D_DIR= 'dataset'\n",
    "model_dir = os.path.join(MODELS_LOCATION, MODEL_NAME)\n",
    "datadir = os.path.join(MODELS_LOCATION, D_DIR)\n",
    "\n",
    "DATA_URL = 'https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'\n",
    "_HEIGHT = 32\n",
    "_WIDTH = 32\n",
    "_NUM_CHANNELS = 3\n",
    "_DEFAULT_IMAGE_BYTES = _HEIGHT * _WIDTH * _NUM_CHANNELS\n",
    "# The record is the image plus a one-byte label\n",
    "_RECORD_BYTES = _DEFAULT_IMAGE_BYTES + 1\n",
    "_NUM_CLASSES = 10\n",
    "_NUM_DATA_FILES = 5\n",
    "\n",
    "_NUM_IMAGES = {\n",
    "    'train': 50000,\n",
    "    'validation': 10000,\n",
    "}\n",
    "\n",
    "DATASET_NAME = 'CIFAR-10'\n",
    "\n",
    "print(model_dir)\n",
    "\n",
    "def checkdata(FLAGS):  \n",
    "  \"\"\"Download and extract the tarball from Alex's website.\"\"\"\n",
    "  if not os.path.exists(FLAGS.data_dir):\n",
    "    os.makedirs(FLAGS.data_dir)\n",
    "\n",
    "  filename = DATA_URL.split('/')[-1]\n",
    "  filepath = os.path.join(FLAGS.data_dir, filename)\n",
    "\n",
    "  if not os.path.exists(filepath):\n",
    "    def _progress(count, block_size, total_size):\n",
    "      sys.stdout.write('\\r>> Downloading %s %.1f%%' % (\n",
    "          filename, 100.0 * count * block_size / total_size))\n",
    "      sys.stdout.flush()\n",
    "\n",
    "    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
    "    print()\n",
    "    statinfo = os.stat(filepath)\n",
    "    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "\n",
    "  tarfile.open(filepath, 'r:gz').extractall(FLAGS.data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(is_training, data_dir):\n",
    "  \"\"\"Returns a list of filenames.\"\"\"\n",
    "  data_dir = os.path.join(data_dir, 'cifar-10-batches-bin')\n",
    "\n",
    "  assert os.path.exists(data_dir), (\n",
    "      'Run cifar10_download_and_extract.py first to download and extract the '\n",
    "      'CIFAR-10 data.')\n",
    "\n",
    "  if is_training:\n",
    "    return [\n",
    "        os.path.join(data_dir, 'data_batch_%d.bin' % i)\n",
    "        for i in range(1, _NUM_DATA_FILES + 1)\n",
    "    ]\n",
    "  else:\n",
    "    return [os.path.join(data_dir, 'test_batch.bin')]\n",
    "\n",
    "\n",
    "def parse_record(raw_record, is_training):\n",
    "  \"\"\"Parse CIFAR-10 image and label from a raw record.\"\"\"\n",
    "  # Convert bytes to a vector of uint8 that is record_bytes long.\n",
    "  record_vector = tf.decode_raw(raw_record, tf.uint8)\n",
    "\n",
    "  # The first byte represents the label, which we convert from uint8 to int32\n",
    "  # and then to one-hot.\n",
    "  label = tf.cast(record_vector[0], tf.int32)\n",
    "\n",
    "  # The remaining bytes after the label represent the image, which we reshape\n",
    "  # from [depth * height * width] to [depth, height, width].\n",
    "  depth_major = tf.reshape(record_vector[1:_RECORD_BYTES],\n",
    "                           [_NUM_CHANNELS, _HEIGHT, _WIDTH])\n",
    "\n",
    "  # Convert from [depth, height, width] to [height, width, depth], and cast as\n",
    "  # float32.\n",
    "  image = tf.cast(tf.transpose(depth_major, [1, 2, 0]), tf.float32)\n",
    "\n",
    "  image = preprocess_image(image, is_training)\n",
    "\n",
    "  return image, label\n",
    "\n",
    "\n",
    "def preprocess_image(image, is_training):\n",
    "  \"\"\"Preprocess a single image of layout [height, width, depth].\"\"\"\n",
    "  if is_training:\n",
    "    # Resize the image to add four extra pixels on each side.\n",
    "    image = tf.image.resize_image_with_crop_or_pad(\n",
    "        image, _HEIGHT + 8, _WIDTH + 8)\n",
    "\n",
    "    # Randomly crop a [_HEIGHT, _WIDTH] section of the image.\n",
    "    image = tf.random_crop(image, [_HEIGHT, _WIDTH, _NUM_CHANNELS])\n",
    "\n",
    "    # Randomly flip the image horizontally.\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "  # Subtract off the mean and divide by the variance of the pixels.\n",
    "  image = tf.image.per_image_standardization(image)\n",
    "  return image\n",
    "\n",
    "\n",
    "def input_fn(is_training, data_dir, batch_size, num_epochs=1, num_gpus=None):\n",
    "  \"\"\"Input_fn using the tf.data input pipeline for CIFAR-10 dataset.\n",
    "\n",
    "  Args:\n",
    "    is_training: A boolean denoting whether the input is for training.\n",
    "    data_dir: The directory containing the input data.\n",
    "    batch_size: The number of samples per batch.\n",
    "    num_epochs: The number of epochs to repeat the dataset.\n",
    "    num_gpus: The number of gpus used for training.\n",
    "\n",
    "  Returns:\n",
    "    A dataset that can be used for iteration.\n",
    "  \"\"\"\n",
    "  filenames = get_filenames(is_training, data_dir)\n",
    "  dataset = tf.data.FixedLengthRecordDataset(filenames, _RECORD_BYTES)\n",
    "\n",
    "  return resnet_run_loop.process_record_dataset(\n",
    "      dataset=dataset,\n",
    "      is_training=is_training,\n",
    "      batch_size=batch_size,\n",
    "      shuffle_buffer=_NUM_IMAGES['train'],\n",
    "      parse_record_fn=parse_record,\n",
    "      num_epochs=num_epochs,\n",
    "      num_gpus=num_gpus,\n",
    "      examples_per_epoch=_NUM_IMAGES['train'] if is_training else None\n",
    "  )\n",
    "\n",
    "\n",
    "def get_synth_input_fn():\n",
    "  return resnet_run_loop.get_synth_input_fn(\n",
    "      _HEIGHT, _WIDTH, _NUM_CHANNELS, _NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10Model(resnet_model.Model):\n",
    "  \"\"\"Model class with appropriate defaults for CIFAR-10 data.\"\"\"\n",
    "\n",
    "  def __init__(self, resnet_size, data_format=None, num_classes=_NUM_CLASSES,\n",
    "               resnet_version=resnet_model.DEFAULT_VERSION,\n",
    "               dtype=resnet_model.DEFAULT_DTYPE):\n",
    "    \"\"\"These are the parameters that work for CIFAR-10 data.\n",
    "\n",
    "    Args:\n",
    "      resnet_size: The number of convolutional layers needed in the model.\n",
    "      data_format: Either 'channels_first' or 'channels_last', specifying which\n",
    "        data format to use when setting up the model.\n",
    "      num_classes: The number of output classes needed from the model. This\n",
    "        enables users to extend the same model to their own datasets.\n",
    "      resnet_version: Integer representing which version of the ResNet network\n",
    "      to use. See README for details. Valid values: [1, 2]\n",
    "      dtype: The TensorFlow dtype to use for calculations.\n",
    "\n",
    "    Raises:\n",
    "      ValueError: if invalid resnet_size is chosen\n",
    "    \"\"\"\n",
    "    if resnet_size % 6 != 2:\n",
    "      raise ValueError('resnet_size must be 6n + 2:', resnet_size)\n",
    "\n",
    "    num_blocks = (resnet_size - 2) // 6\n",
    "\n",
    "    super(Cifar10Model, self).__init__(\n",
    "        resnet_size=resnet_size,\n",
    "        bottleneck=False,\n",
    "        num_classes=num_classes,\n",
    "        num_filters=16,\n",
    "        kernel_size=3,\n",
    "        conv_stride=1,\n",
    "        first_pool_size=None,\n",
    "        first_pool_stride=None,\n",
    "        block_sizes=[num_blocks] * 3,\n",
    "        block_strides=[1, 2, 2],\n",
    "        final_size=64,\n",
    "        resnet_version=resnet_version,\n",
    "        data_format=data_format,\n",
    "        dtype=dtype\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar10_model_fn(features, labels, mode, params):\n",
    "  \"\"\"Model function for CIFAR-10.\"\"\"\n",
    "  print(\"feature: {}\".format(features))\n",
    "  if isinstance(features,dict):\n",
    "     features = features['image'] \n",
    "  features = tf.reshape(features, [-1, _HEIGHT, _WIDTH, _NUM_CHANNELS])\n",
    "\n",
    "  learning_rate_fn = resnet_run_loop.learning_rate_with_decay(\n",
    "      batch_size=params['batch_size'], batch_denom=128,\n",
    "      num_images=_NUM_IMAGES['train'], boundary_epochs=[100, 150, 200],\n",
    "      decay_rates=[1, 0.1, 0.01, 0.001])\n",
    "\n",
    "  # We use a weight decay of 0.0002, which performs better\n",
    "  # than the 0.0001 that was originally suggested.\n",
    "  weight_decay = 2e-4\n",
    "\n",
    "  # Empirical testing showed that including batch_normalization variables\n",
    "  # in the calculation of regularized loss helped validation accuracy\n",
    "  # for the CIFAR-10 dataset, perhaps because the regularization prevents\n",
    "  # overfitting on the small data set. We therefore include all vars when\n",
    "  # regularizing and computing loss during training.\n",
    "  def loss_filter_fn(_):\n",
    "    return True\n",
    "\n",
    "  return resnet_run_loop.resnet_model_fn(\n",
    "      features=features,\n",
    "      labels=labels,\n",
    "      mode=mode,\n",
    "      model_class=Cifar10Model,\n",
    "      resnet_size=params['resnet_size'],\n",
    "      weight_decay=weight_decay,\n",
    "      learning_rate_fn=learning_rate_fn,\n",
    "      momentum=0.9,\n",
    "      data_format=params['data_format'],\n",
    "      resnet_version=params['resnet_version'],\n",
    "      loss_scale=params['loss_scale'],\n",
    "      loss_filter_fn=loss_filter_fn,\n",
    "      dtype=params['dtype'],\n",
    "      fine_tune=params['fine_tune']\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Train and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Experiment Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cifar(flags_obj):\n",
    "  \"\"\"Run ResNet CIFAR-10 training and eval loop.\n",
    "\n",
    "  Args:\n",
    "    flags_obj: An object containing parsed flag values.\n",
    "  \"\"\"\n",
    "  input_function = (flags_obj.use_synthetic_data and get_synth_input_fn()\n",
    "                    or input_fn)\n",
    "  return resnet_run_loop.resnet_main(\n",
    "      flags_obj, cifar10_model_fn, input_function, DATASET_NAME,\n",
    "      shape=[_HEIGHT, _WIDTH, _NUM_CHANNELS])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3 Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Downloading cifar-10-binary.tar.gz 100.0%\n",
      "Successfully downloaded cifar-10-binary.tar.gz 170052171 bytes.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 14:57:11.892715  1928 run_config.py:532] Initializing RunConfig with distribution strategies.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 14:57:11.893713  1928 estimator_training.py:166] Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002028696EAC8>, '_session_config': allow_soft_placement: true\n",
      ", '_evaluation_master': '', '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_eval_distribute': None, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.one_device_strategy.OneDeviceStrategy object at 0x0000020287A8F358>, '_save_checkpoints_steps': None, '_global_id_in_cluster': 0, '_task_type': 'worker', '_distribute_coordinator_mode': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_save_checkpoints_secs': 600, '_task_id': 0, '_device_fn': None, '_model_dir': 'models\\\\resnet\\\\dnn', '_master': '', '_is_chief': True, '_experimental_distribute': None, '_protocol': None, '_service': None, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 14:57:11.895707  1928 estimator.py:201] Using config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002028696EAC8>, '_session_config': allow_soft_placement: true\n",
      ", '_evaluation_master': '', '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_eval_distribute': None, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.one_device_strategy.OneDeviceStrategy object at 0x0000020287A8F358>, '_save_checkpoints_steps': None, '_global_id_in_cluster': 0, '_task_type': 'worker', '_distribute_coordinator_mode': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_save_checkpoints_secs': 600, '_task_id': 0, '_device_fn': None, '_model_dir': 'models\\\\resnet\\\\dnn', '_master': '', '_is_chief': True, '_experimental_distribute': None, '_protocol': None, '_service': None, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Benchmark run: {'machine_config': {'cpu_info': {'cpu_info': 'Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz', 'mhz_per_cpu': 1600.0, 'num_cores': 8}, 'gpu_info': {'count': 0}, 'memory_available': 3000918016, 'memory_total': 8436670464}, 'run_date': '2019-05-06T21:57:11.896706Z', 'tensorflow_version': {'git_hash': \"b'unknown'\", 'version': '1.13.1'}, 'test_id': None, 'run_parameters': [{'name': 'batch_size', 'long_value': 128}, {'name': 'dtype', 'string_value': \"<dtype: 'float32'>\"}, {'name': 'resnet_size', 'string_value': '32'}, {'name': 'resnet_version', 'string_value': '2'}, {'name': 'synthetic_data', 'bool_value': 'False'}, {'name': 'train_epochs', 'long_value': 2}], 'tensorflow_environment_variables': [{'name': 'TF_ENABLE_WINOGRAD_NONFUSED', 'value': '1'}], 'model_name': 'resnet', 'dataset': {'name': 'CIFAR-10'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 14:57:15.993318  1928 logger.py:151] Benchmark run: {'machine_config': {'cpu_info': {'cpu_info': 'Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz', 'mhz_per_cpu': 1600.0, 'num_cores': 8}, 'gpu_info': {'count': 0}, 'memory_available': 3000918016, 'memory_total': 8436670464}, 'run_date': '2019-05-06T21:57:11.896706Z', 'tensorflow_version': {'git_hash': \"b'unknown'\", 'version': '1.13.1'}, 'test_id': None, 'run_parameters': [{'name': 'batch_size', 'long_value': 128}, {'name': 'dtype', 'string_value': \"<dtype: 'float32'>\"}, {'name': 'resnet_size', 'string_value': '32'}, {'name': 'resnet_version', 'string_value': '2'}, {'name': 'synthetic_data', 'bool_value': 'False'}, {'name': 'train_epochs', 'long_value': 2}], 'tensorflow_environment_variables': [{'name': 'TF_ENABLE_WINOGRAD_NONFUSED', 'value': '1'}], 'model_name': 'resnet', 'dataset': {'name': 'CIFAR-10'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000020287ABDD68>, '_session_config': allow_soft_placement: true\n",
      ", '_evaluation_master': '', '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_eval_distribute': None, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.one_device_strategy.OneDeviceStrategy object at 0x0000020287ABDE80>, '_save_checkpoints_steps': None, '_global_id_in_cluster': 0, '_task_type': 'worker', '_distribute_coordinator_mode': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_save_checkpoints_secs': 600, '_task_id': 0, '_device_fn': None, '_model_dir': 'models\\\\resnet\\\\dnn', '_master': '', '_is_chief': True, '_experimental_distribute': None, '_protocol': None, '_service': None, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 14:57:15.999259  1928 estimator.py:201] Using config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000020287ABDD68>, '_session_config': allow_soft_placement: true\n",
      ", '_evaluation_master': '', '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_eval_distribute': None, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.one_device_strategy.OneDeviceStrategy object at 0x0000020287ABDE80>, '_save_checkpoints_steps': None, '_global_id_in_cluster': 0, '_task_type': 'worker', '_distribute_coordinator_mode': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_save_checkpoints_secs': 600, '_task_id': 0, '_device_fn': None, '_model_dir': 'models\\\\resnet\\\\dnn', '_master': '', '_is_chief': True, '_experimental_distribute': None, '_protocol': None, '_service': None, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting cycle: 0/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 14:57:16.002240  1928 resnet_run_loop.py:482] Starting cycle: 0/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\tmp\\git\\models\\official\\resnet\\resnet_run_loop.py:98: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0506 14:57:16.072904  1928 deprecation.py:323] From C:\\tmp\\git\\models\\official\\resnet\\resnet_run_loop.py:98: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\steve\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0506 14:57:16.133448  1928 deprecation.py:323] From c:\\users\\steve\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\steve\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:1241: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0506 14:57:16.229541  1928 deprecation.py:323] From c:\\users\\steve\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:1241: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 14:57:16.487293  1928 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 14:57:16.488329  1928 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: Tensor(\"IteratorGetNext:0\", shape=(?, 32, 32, 3), dtype=float32, device=/device:CPU:0)\n",
      "WARNING:tensorflow:From C:\\tmp\\git\\models\\official\\resnet\\resnet_model.py:95: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0506 14:57:16.495277  1928 deprecation.py:323] From C:\\tmp\\git\\models\\official\\resnet\\resnet_model.py:95: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\tmp\\git\\models\\official\\resnet\\resnet_model.py:54: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0506 14:57:16.527101  1928 deprecation.py:323] From C:\\tmp\\git\\models\\official\\resnet\\resnet_model.py:54: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\tmp\\git\\models\\official\\resnet\\resnet_model.py:546: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0506 14:57:18.108753  1928 deprecation.py:323] From C:\\tmp\\git\\models\\official\\resnet\\resnet_model.py:546: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\steve\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0506 14:57:18.145655  1928 deprecation.py:323] From c:\\users\\steve\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\steve\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0506 14:57:18.599140  1928 deprecation.py:323] From c:\\users\\steve\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 14:57:19.863752  1928 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 14:57:19.864749  1928 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 14:57:20.099123  1928 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 14:57:20.965530  1928 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 14:57:21.551629  1928 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 14:57:21.620287  1928 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into models\\resnet\\dnn\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 14:57:23.218422  1928 basic_session_run_hooks.py:594] Saving checkpoints for 0 into models\\resnet\\dnn\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize strategy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 14:57:23.854934  1928 util.py:164] Initialize strategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:cross_entropy = 2.397293, learning_rate = 0.1, train_accuracy = 0.1015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 14:57:29.112064  1928 basic_session_run_hooks.py:249] cross_entropy = 2.397293, learning_rate = 0.1, train_accuracy = 0.1015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.6375375, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 14:57:29.115056  1928 basic_session_run_hooks.py:249] loss = 2.6375375, step = 0\n"
     ]
    }
   ],
   "source": [
    "def define_cifar_flags():\n",
    "    resnet_run_loop.define_resnet_flags()\n",
    "    flags.adopt_module_key_flags(resnet_run_loop)\n",
    "    flags_core.set_defaults(data_dir=datadir,\n",
    "                          model_dir=model_dir,\n",
    "                          resnet_size='32',\n",
    "                          train_epochs=2,\n",
    "                          epochs_between_evals=1,\n",
    "                          batch_size=128)\n",
    "\n",
    "define_cifar_flags()\n",
    "\n",
    "if tf.gfile.Exists(model_dir):\n",
    "    print(\"Removing previous artifacts...\")\n",
    "    tf.gfile.DeleteRecursively(model_dir)\n",
    "\n",
    "sys.argv = \"-f test\".split(\" \")\n",
    "flags.FLAGS(sys.argv)\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "checkdata(flags.FLAGS)\n",
    "estimator = run_cifar(flags.FLAGS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 10:23:13.596155 46044 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: {'image': <tf.Tensor 'image:0' shape=(?, 32, 32, 3) dtype=float32>}\n",
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 10:23:14.553626 46044 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\steve\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\saved_model\\signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0506 10:23:14.554592 46044 deprecation.py:323] From c:\\users\\steve\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\saved_model\\signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 10:23:14.556592 46044 export.py:587] Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 10:23:14.557586 46044 export.py:587] Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict', 'serving_default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 10:23:14.558584 46044 export.py:587] Signatures INCLUDED in export for Predict: ['predict', 'serving_default']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 10:23:14.559579 46044 export.py:587] Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 10:23:14.560577 46044 export.py:587] Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models\\resnet\\dnn\\model.ckpt-782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 10:23:14.730169 46044 saver.py:1270] Restoring parameters from models\\resnet\\dnn\\model.ckpt-782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 10:23:14.871752 46044 builder_impl.py:654] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 10:23:14.872750 46044 builder_impl.py:449] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: models\\resnet\\dnn\\export\\temp-b'1557163393'\\saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0506 10:23:15.086852 46044 builder_impl.py:414] SavedModel written to: models\\resnet\\dnn\\export\\temp-b'1557163393'\\saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'models\\\\resnet\\\\dnn\\\\export\\\\1557163393'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_serving_input_receiver_fn():\n",
    "    inputs = {'image':tf.placeholder(shape=[None,_HEIGHT, _WIDTH,_NUM_CHANNELS], dtype=tf.float32, name='image')}\n",
    "    return tf.estimator.export.build_raw_serving_input_receiver_fn(inputs)\n",
    "\n",
    "export_dir = os.path.join(model_dir, 'export')\n",
    "\n",
    "if tf.gfile.Exists(export_dir):\n",
    "    tf.gfile.DeleteRecursively(export_dir)\n",
    "        \n",
    "estimator.export_savedmodel(\n",
    "    export_dir_base=export_dir,\n",
    "    serving_input_receiver_fn=make_serving_input_receiver_fn()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inspect the Exported SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/resnet/dnn/export/1557163393\n",
      "saved_model.pb\n",
      "variables\n",
      "\r\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\r\n",
      "\r\n",
      "signature_def['predict']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "    inputs['image'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 32, 32, 3)\r\n",
      "        name: image:0\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['class_ids'] tensor_info:\r\n",
      "        dtype: DT_INT64\r\n",
      "        shape: (-1, 1)\r\n",
      "        name: strided_slice:0\r\n",
      "    outputs['classes'] tensor_info:\r\n",
      "        dtype: DT_INT64\r\n",
      "        shape: (-1)\r\n",
      "        name: ArgMax_2:0\r\n",
      "    outputs['probabilities'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 10)\r\n",
      "        name: softmax_tensor_1:0\r\n",
      "  Method name is: tensorflow/serving/predict\r\n",
      "\r\n",
      "signature_def['serving_default']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "    inputs['image'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 32, 32, 3)\r\n",
      "        name: image:0\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['class_ids'] tensor_info:\r\n",
      "        dtype: DT_INT64\r\n",
      "        shape: (-1, 1)\r\n",
      "        name: strided_slice:0\r\n",
      "    outputs['classes'] tensor_info:\r\n",
      "        dtype: DT_INT64\r\n",
      "        shape: (-1)\r\n",
      "        name: ArgMax_2:0\r\n",
      "    outputs['probabilities'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 10)\r\n",
      "        name: softmax_tensor_1:0\r\n",
      "  Method name is: tensorflow/serving/predict\r\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "saved_models_base=models/resnet/dnn/export/\n",
    "saved_model_dir=${saved_models_base}$(ls ${saved_models_base} | tail -n 1)\n",
    "echo ${saved_model_dir}\n",
    "ls ${saved_model_dir}\n",
    "saved_model_cli show --dir=${saved_model_dir} --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction with SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_test(saved_model_dir, signature=\"predict\", input_name='image', batch_size=300, repeat=100):\n",
    "\n",
    "#    es = dataset.test(datadir)\n",
    "#    iter = images.make_one_shot_iterator()\n",
    "    #print (\"Eval data shape: {}\".format(eval_data.shape))\n",
    "#    eval_data, eval_labels = iter.get_next()\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "    \n",
    "    time_start = datetime.utcnow() \n",
    "    \n",
    "    predictor = tf.contrib.predictor.from_saved_model(\n",
    "        export_dir = saved_model_dir,\n",
    "        signature_def_key=signature\n",
    "    )\n",
    "    time_end = datetime.utcnow() \n",
    "        \n",
    "    time_elapsed = time_end - time_start\n",
    "   \n",
    "    print (\"\")\n",
    "    print(\"Model loading time: {} seconds\".format(time_elapsed.total_seconds()))\n",
    "    print (\"\")\n",
    "    \n",
    "    time_start = datetime.utcnow() \n",
    "    output = None\n",
    "#    def eval_input_fn():\n",
    "#        return dataset.test(datadir).batch(\n",
    "#            batch_size).make_one_shot_iterator().get_next()       \n",
    "    \n",
    "    def eval_input_fn():\n",
    "        input_function = (flags.FLAGS.use_synthetic_data and get_synth_input_fn()\n",
    "                    or input_fn)        \n",
    "        return input_function(is_training=False, data_dir=flags.FLAGS.data_dir,\n",
    "            batch_size=batch_size,\n",
    "                num_epochs=1).make_one_shot_iterator().get_next()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        for i in range(repeat):\n",
    "            input_images, labels = sess.run(eval_input_fn())        \n",
    "            #print(input_images[0])\n",
    "            input_images = input_images.reshape(batch_size, _HEIGHT, _WIDTH, _NUM_CHANNELS)\n",
    "            output = predictor(\n",
    "                {\n",
    "                    input_name: input_images\n",
    "                }\n",
    "            )\n",
    "    \n",
    "    time_end = datetime.utcnow() \n",
    "\n",
    "    time_elapsed_sec = (time_end - time_start).total_seconds()\n",
    "    \n",
    "    print (\"Inference elapsed time: {} seconds\".format(time_elapsed_sec))\n",
    "    print (\"\")\n",
    "    #print (\"output {}\".format(output))\n",
    "    print (\"Prediction produced for {} instances batch, repeated {} times\".format(len(output['class_ids']), repeat))\n",
    "    print (\"Average latency per batch: {} seconds\".format(time_elapsed_sec/repeat))\n",
    "    print (\"\")\n",
    "    \n",
    "    print (\"Prediction output for the last instance:\")\n",
    "    for key in output.keys():\n",
    "        print (\"{}: {}\".format(key,output[key][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Prediction with SavedModel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\\resnet\\dnn\\export\\1557163393\n",
      "\n",
      "Model loading time: 0.452602 seconds\n",
      "\n",
      "Inference elapsed time: 264.680527 seconds\n",
      "\n",
      "Prediction produced for 300 instances batch, repeated 100 times\n",
      "Average latency per batch: 2.6468052699999998 seconds\n",
      "\n",
      "Prediction output for the last instance:\n",
      "classes: 9\n",
      "class_ids: [9]\n",
      "probabilities: [1.2987635e-02 2.2308657e-01 3.0801960e-04 4.4191489e-03 2.3142706e-05\n",
      " 1.4559949e-03 1.7188782e-03 4.6349727e-04 7.1629445e-05 7.5546551e-01]\n"
     ]
    }
   ],
   "source": [
    "saved_model_dir = os.path.join(export_dir, os.listdir(export_dir)[-1]) \n",
    "print(saved_model_dir)\n",
    "inference_test(saved_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe GraphDef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_graph(graph_def, show_nodes=False):\n",
    "    \n",
    "    print ('Input Feature Nodes: {}'.format([node.name for node in graph_def.node if node.op=='Placeholder']))\n",
    "    print (\"\")\n",
    "    print ('Unused Nodes: {}'.format([node.name for node in graph_def.node if 'unused'  in node.name]))\n",
    "    print (\"\")\n",
    "    print ('Output Nodes: {}'.format( [node.name for node in graph_def.node if 'predictions' in node.name]))\n",
    "    print (\"\")\n",
    "    print ('Quanitization Nodes: {}'.format( [node.name for node in graph_def.node if 'quant' in node.name]))\n",
    "    print (\"\")\n",
    "    print ('Constant Count: {}'.format( len([node for node in graph_def.node if node.op=='Const'])))\n",
    "    print (\"\")\n",
    "    print ('Variable Count: {}'.format( len([node for node in graph_def.node if 'Variable' in node.op])))\n",
    "    print (\"\")\n",
    "    print ('Identity Count: {}'.format( len([node for node in graph_def.node if node.op=='Identity'])))\n",
    "    print (\"\")\n",
    "    print ('Total nodes: {}'.format( len(graph_def.node)))\n",
    "    print ('')\n",
    "    node_names = [node.name for node in graph_def.node if node.op=='Identity']\n",
    "    print(node_names)\n",
    "\n",
    "    if show_nodes==True:\n",
    "        for node in graph_def.node:\n",
    "            print ('Op:{} - Name: {}'.format(node.op, node.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Describe the SavedModel Graph (before optimisation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GraphDef from a SavedModel Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_def_from_saved_model(saved_model_dir):\n",
    "    \n",
    "    print (saved_model_dir)\n",
    "    print (\"\")\n",
    "    \n",
    "    from tensorflow.python.saved_model import tag_constants\n",
    "    \n",
    "    with tf.Session() as session:\n",
    "        meta_graph_def = tf.saved_model.loader.load(\n",
    "            session,\n",
    "            tags=[tag_constants.SERVING],\n",
    "            export_dir=saved_model_dir\n",
    "        )\n",
    "        \n",
    "    return meta_graph_def.graph_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\\resnet\\dnn\\export\\1557163393\n",
      "\n",
      "Input Feature Nodes: ['image']\n",
      "\n",
      "Unused Nodes: []\n",
      "\n",
      "Output Nodes: []\n",
      "\n",
      "Quanitization Nodes: []\n",
      "\n",
      "Constant Count: 318\n",
      "\n",
      "Variable Count: 161\n",
      "\n",
      "Identity Count: 169\n",
      "\n",
      "Total nodes: 1218\n",
      "\n",
      "['global_step/read', 'resnet_model/conv2d/kernel/read', 'resnet_model/initial_conv', 'resnet_model/batch_normalization/gamma/read', 'resnet_model/batch_normalization/beta/read', 'resnet_model/batch_normalization/moving_mean/read', 'resnet_model/batch_normalization/moving_variance/read', 'resnet_model/conv2d_1/kernel/read', 'resnet_model/conv2d_2/kernel/read', 'resnet_model/batch_normalization_1/gamma/read', 'resnet_model/batch_normalization_1/beta/read', 'resnet_model/batch_normalization_1/moving_mean/read', 'resnet_model/batch_normalization_1/moving_variance/read', 'resnet_model/conv2d_3/kernel/read', 'resnet_model/batch_normalization_2/gamma/read', 'resnet_model/batch_normalization_2/beta/read', 'resnet_model/batch_normalization_2/moving_mean/read', 'resnet_model/batch_normalization_2/moving_variance/read', 'resnet_model/conv2d_4/kernel/read', 'resnet_model/batch_normalization_3/gamma/read', 'resnet_model/batch_normalization_3/beta/read', 'resnet_model/batch_normalization_3/moving_mean/read', 'resnet_model/batch_normalization_3/moving_variance/read', 'resnet_model/conv2d_5/kernel/read', 'resnet_model/batch_normalization_4/gamma/read', 'resnet_model/batch_normalization_4/beta/read', 'resnet_model/batch_normalization_4/moving_mean/read', 'resnet_model/batch_normalization_4/moving_variance/read', 'resnet_model/conv2d_6/kernel/read', 'resnet_model/batch_normalization_5/gamma/read', 'resnet_model/batch_normalization_5/beta/read', 'resnet_model/batch_normalization_5/moving_mean/read', 'resnet_model/batch_normalization_5/moving_variance/read', 'resnet_model/conv2d_7/kernel/read', 'resnet_model/batch_normalization_6/gamma/read', 'resnet_model/batch_normalization_6/beta/read', 'resnet_model/batch_normalization_6/moving_mean/read', 'resnet_model/batch_normalization_6/moving_variance/read', 'resnet_model/conv2d_8/kernel/read', 'resnet_model/batch_normalization_7/gamma/read', 'resnet_model/batch_normalization_7/beta/read', 'resnet_model/batch_normalization_7/moving_mean/read', 'resnet_model/batch_normalization_7/moving_variance/read', 'resnet_model/conv2d_9/kernel/read', 'resnet_model/batch_normalization_8/gamma/read', 'resnet_model/batch_normalization_8/beta/read', 'resnet_model/batch_normalization_8/moving_mean/read', 'resnet_model/batch_normalization_8/moving_variance/read', 'resnet_model/conv2d_10/kernel/read', 'resnet_model/batch_normalization_9/gamma/read', 'resnet_model/batch_normalization_9/beta/read', 'resnet_model/batch_normalization_9/moving_mean/read', 'resnet_model/batch_normalization_9/moving_variance/read', 'resnet_model/conv2d_11/kernel/read', 'resnet_model/block_layer1', 'resnet_model/batch_normalization_10/gamma/read', 'resnet_model/batch_normalization_10/beta/read', 'resnet_model/batch_normalization_10/moving_mean/read', 'resnet_model/batch_normalization_10/moving_variance/read', 'resnet_model/conv2d_12/kernel/read', 'resnet_model/conv2d_13/kernel/read', 'resnet_model/batch_normalization_11/gamma/read', 'resnet_model/batch_normalization_11/beta/read', 'resnet_model/batch_normalization_11/moving_mean/read', 'resnet_model/batch_normalization_11/moving_variance/read', 'resnet_model/conv2d_14/kernel/read', 'resnet_model/batch_normalization_12/gamma/read', 'resnet_model/batch_normalization_12/beta/read', 'resnet_model/batch_normalization_12/moving_mean/read', 'resnet_model/batch_normalization_12/moving_variance/read', 'resnet_model/conv2d_15/kernel/read', 'resnet_model/batch_normalization_13/gamma/read', 'resnet_model/batch_normalization_13/beta/read', 'resnet_model/batch_normalization_13/moving_mean/read', 'resnet_model/batch_normalization_13/moving_variance/read', 'resnet_model/conv2d_16/kernel/read', 'resnet_model/batch_normalization_14/gamma/read', 'resnet_model/batch_normalization_14/beta/read', 'resnet_model/batch_normalization_14/moving_mean/read', 'resnet_model/batch_normalization_14/moving_variance/read', 'resnet_model/conv2d_17/kernel/read', 'resnet_model/batch_normalization_15/gamma/read', 'resnet_model/batch_normalization_15/beta/read', 'resnet_model/batch_normalization_15/moving_mean/read', 'resnet_model/batch_normalization_15/moving_variance/read', 'resnet_model/conv2d_18/kernel/read', 'resnet_model/batch_normalization_16/gamma/read', 'resnet_model/batch_normalization_16/beta/read', 'resnet_model/batch_normalization_16/moving_mean/read', 'resnet_model/batch_normalization_16/moving_variance/read', 'resnet_model/conv2d_19/kernel/read', 'resnet_model/batch_normalization_17/gamma/read', 'resnet_model/batch_normalization_17/beta/read', 'resnet_model/batch_normalization_17/moving_mean/read', 'resnet_model/batch_normalization_17/moving_variance/read', 'resnet_model/conv2d_20/kernel/read', 'resnet_model/batch_normalization_18/gamma/read', 'resnet_model/batch_normalization_18/beta/read', 'resnet_model/batch_normalization_18/moving_mean/read', 'resnet_model/batch_normalization_18/moving_variance/read', 'resnet_model/conv2d_21/kernel/read', 'resnet_model/batch_normalization_19/gamma/read', 'resnet_model/batch_normalization_19/beta/read', 'resnet_model/batch_normalization_19/moving_mean/read', 'resnet_model/batch_normalization_19/moving_variance/read', 'resnet_model/conv2d_22/kernel/read', 'resnet_model/block_layer2', 'resnet_model/batch_normalization_20/gamma/read', 'resnet_model/batch_normalization_20/beta/read', 'resnet_model/batch_normalization_20/moving_mean/read', 'resnet_model/batch_normalization_20/moving_variance/read', 'resnet_model/conv2d_23/kernel/read', 'resnet_model/conv2d_24/kernel/read', 'resnet_model/batch_normalization_21/gamma/read', 'resnet_model/batch_normalization_21/beta/read', 'resnet_model/batch_normalization_21/moving_mean/read', 'resnet_model/batch_normalization_21/moving_variance/read', 'resnet_model/conv2d_25/kernel/read', 'resnet_model/batch_normalization_22/gamma/read', 'resnet_model/batch_normalization_22/beta/read', 'resnet_model/batch_normalization_22/moving_mean/read', 'resnet_model/batch_normalization_22/moving_variance/read', 'resnet_model/conv2d_26/kernel/read', 'resnet_model/batch_normalization_23/gamma/read', 'resnet_model/batch_normalization_23/beta/read', 'resnet_model/batch_normalization_23/moving_mean/read', 'resnet_model/batch_normalization_23/moving_variance/read', 'resnet_model/conv2d_27/kernel/read', 'resnet_model/batch_normalization_24/gamma/read', 'resnet_model/batch_normalization_24/beta/read', 'resnet_model/batch_normalization_24/moving_mean/read', 'resnet_model/batch_normalization_24/moving_variance/read', 'resnet_model/conv2d_28/kernel/read', 'resnet_model/batch_normalization_25/gamma/read', 'resnet_model/batch_normalization_25/beta/read', 'resnet_model/batch_normalization_25/moving_mean/read', 'resnet_model/batch_normalization_25/moving_variance/read', 'resnet_model/conv2d_29/kernel/read', 'resnet_model/batch_normalization_26/gamma/read', 'resnet_model/batch_normalization_26/beta/read', 'resnet_model/batch_normalization_26/moving_mean/read', 'resnet_model/batch_normalization_26/moving_variance/read', 'resnet_model/conv2d_30/kernel/read', 'resnet_model/batch_normalization_27/gamma/read', 'resnet_model/batch_normalization_27/beta/read', 'resnet_model/batch_normalization_27/moving_mean/read', 'resnet_model/batch_normalization_27/moving_variance/read', 'resnet_model/conv2d_31/kernel/read', 'resnet_model/batch_normalization_28/gamma/read', 'resnet_model/batch_normalization_28/beta/read', 'resnet_model/batch_normalization_28/moving_mean/read', 'resnet_model/batch_normalization_28/moving_variance/read', 'resnet_model/conv2d_32/kernel/read', 'resnet_model/batch_normalization_29/gamma/read', 'resnet_model/batch_normalization_29/beta/read', 'resnet_model/batch_normalization_29/moving_mean/read', 'resnet_model/batch_normalization_29/moving_variance/read', 'resnet_model/conv2d_33/kernel/read', 'resnet_model/block_layer3', 'resnet_model/batch_normalization_30/gamma/read', 'resnet_model/batch_normalization_30/beta/read', 'resnet_model/batch_normalization_30/moving_mean/read', 'resnet_model/batch_normalization_30/moving_variance/read', 'resnet_model/final_reduce_mean', 'resnet_model/dense/kernel/read', 'resnet_model/dense/bias/read', 'resnet_model/final_dense', 'save/control_dependency', 'save/Identity']\n"
     ]
    }
   ],
   "source": [
    "describe_graph(get_graph_def_from_saved_model(saved_model_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(model_dir):\n",
    "    \n",
    "    print (model_dir)\n",
    "    print (\"\")\n",
    "    \n",
    "    pb_size = os.path.getsize(os.path.join(model_dir,'saved_model.pb'))\n",
    "    \n",
    "    variables_size = 0\n",
    "    if os.path.exists(os.path.join(model_dir,'variables/variables.data-00000-of-00001')):\n",
    "        variables_size = os.path.getsize(os.path.join(model_dir,'variables/variables.data-00000-of-00001'))\n",
    "        variables_size += os.path.getsize(os.path.join(model_dir,'variables/variables.index'))\n",
    "\n",
    "    print (\"Model size: {} KB\".format(round(pb_size/(1024.0),3)))\n",
    "    print (\"Variables size: {} KB\".format(round( variables_size/(1024.0),3)))\n",
    "    print (\"Total Size: {} KB\".format(round((pb_size + variables_size)/(1024.0),3)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\\resnet\\dnn\\export\\1557163393\n",
      "\n",
      "Model size: 350.947 KB\n",
      "Variables size: 1838.546 KB\n",
      "Total Size: 2189.493 KB\n"
     ]
    }
   ],
   "source": [
    "get_size(saved_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Freeze SavedModel\n",
    "\n",
    "This function will convert the SavedModel into a GraphDef file (freezed_model.pb), and storing the variables as constrant to the freezed_model.pb\n",
    "\n",
    "You need to define the graph output nodes for freezing. We are only interested in the **class_id**, which is produced by **head/predictions/ExpandDims** node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_graph(saved_model_dir):\n",
    "    \n",
    "    from tensorflow.python.tools import freeze_graph\n",
    "    from tensorflow.python.saved_model import tag_constants\n",
    "    \n",
    "    output_graph_filename = os.path.join(saved_model_dir, \"freezed_model.pb\")\n",
    "#    output_node_names = \"head/predictions/ExpandDims\"\n",
    "#    output_node_names = \"PREDICT/predictions/probabilities\"\n",
    "    output_node_names = \"strided_slice\"\n",
    "    \n",
    "    initializer_nodes = \"\"\n",
    "\n",
    "    freeze_graph.freeze_graph(\n",
    "        input_saved_model_dir=saved_model_dir,\n",
    "        output_graph=output_graph_filename,\n",
    "        saved_model_tags = tag_constants.SERVING,\n",
    "        output_node_names=output_node_names,\n",
    "        initializer_nodes=initializer_nodes,\n",
    "\n",
    "        input_graph=None, \n",
    "        input_saver=False,\n",
    "        input_binary=False, \n",
    "        input_checkpoint=None, \n",
    "        restore_op_name=None, \n",
    "        filename_tensor_name=None, \n",
    "        clear_devices=False,\n",
    "        input_meta_graph=False,\n",
    "    )\n",
    "    \n",
    "    print (\"SavedModel graph freezed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SavedModel graph freezed!\n"
     ]
    }
   ],
   "source": [
    "node_names = [node.name for node in tf.get_default_graph().as_graph_def().node]\n",
    "\n",
    "freeze_graph(saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/mnist/cnn_classifier/export/1556574193\n",
      "freezed_model.pb\n",
      "optimised_model.pb\n",
      "saved_model.pb\n",
      "variables\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "saved_models_base=models/mnist/cnn_classifier/export/\n",
    "saved_model_dir=${saved_models_base}$(ls ${saved_models_base} | tail -n 1)\n",
    "echo ${saved_model_dir}\n",
    "ls ${saved_model_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Describe the freezed_model.pb Graph (after freezing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GraphDef from GraphDef File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_def_from_file(graph_filepath):\n",
    "    \n",
    "    print (graph_filepath)\n",
    "    print (\"\")\n",
    "    \n",
    "    from tensorflow.python import ops\n",
    "    \n",
    "    with ops.Graph().as_default():\n",
    "        with tf.gfile.GFile(graph_filepath, \"rb\") as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            \n",
    "            return graph_def\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\\resnet\\dnn\\export\\1557163393\\freezed_model.pb\n",
      "\n",
      "Input Feature Nodes: ['image']\n",
      "\n",
      "Unused Nodes: []\n",
      "\n",
      "Output Nodes: []\n",
      "\n",
      "Quanitization Nodes: []\n",
      "\n",
      "Constant Count: 171\n",
      "\n",
      "Variable Count: 0\n",
      "\n",
      "Identity Count: 166\n",
      "\n",
      "Total nodes: 460\n",
      "\n",
      "['resnet_model/conv2d/kernel/read', 'resnet_model/initial_conv', 'resnet_model/batch_normalization/gamma/read', 'resnet_model/batch_normalization/beta/read', 'resnet_model/batch_normalization/moving_mean/read', 'resnet_model/batch_normalization/moving_variance/read', 'resnet_model/conv2d_1/kernel/read', 'resnet_model/conv2d_2/kernel/read', 'resnet_model/batch_normalization_1/gamma/read', 'resnet_model/batch_normalization_1/beta/read', 'resnet_model/batch_normalization_1/moving_mean/read', 'resnet_model/batch_normalization_1/moving_variance/read', 'resnet_model/conv2d_3/kernel/read', 'resnet_model/batch_normalization_2/gamma/read', 'resnet_model/batch_normalization_2/beta/read', 'resnet_model/batch_normalization_2/moving_mean/read', 'resnet_model/batch_normalization_2/moving_variance/read', 'resnet_model/conv2d_4/kernel/read', 'resnet_model/batch_normalization_3/gamma/read', 'resnet_model/batch_normalization_3/beta/read', 'resnet_model/batch_normalization_3/moving_mean/read', 'resnet_model/batch_normalization_3/moving_variance/read', 'resnet_model/conv2d_5/kernel/read', 'resnet_model/batch_normalization_4/gamma/read', 'resnet_model/batch_normalization_4/beta/read', 'resnet_model/batch_normalization_4/moving_mean/read', 'resnet_model/batch_normalization_4/moving_variance/read', 'resnet_model/conv2d_6/kernel/read', 'resnet_model/batch_normalization_5/gamma/read', 'resnet_model/batch_normalization_5/beta/read', 'resnet_model/batch_normalization_5/moving_mean/read', 'resnet_model/batch_normalization_5/moving_variance/read', 'resnet_model/conv2d_7/kernel/read', 'resnet_model/batch_normalization_6/gamma/read', 'resnet_model/batch_normalization_6/beta/read', 'resnet_model/batch_normalization_6/moving_mean/read', 'resnet_model/batch_normalization_6/moving_variance/read', 'resnet_model/conv2d_8/kernel/read', 'resnet_model/batch_normalization_7/gamma/read', 'resnet_model/batch_normalization_7/beta/read', 'resnet_model/batch_normalization_7/moving_mean/read', 'resnet_model/batch_normalization_7/moving_variance/read', 'resnet_model/conv2d_9/kernel/read', 'resnet_model/batch_normalization_8/gamma/read', 'resnet_model/batch_normalization_8/beta/read', 'resnet_model/batch_normalization_8/moving_mean/read', 'resnet_model/batch_normalization_8/moving_variance/read', 'resnet_model/conv2d_10/kernel/read', 'resnet_model/batch_normalization_9/gamma/read', 'resnet_model/batch_normalization_9/beta/read', 'resnet_model/batch_normalization_9/moving_mean/read', 'resnet_model/batch_normalization_9/moving_variance/read', 'resnet_model/conv2d_11/kernel/read', 'resnet_model/block_layer1', 'resnet_model/batch_normalization_10/gamma/read', 'resnet_model/batch_normalization_10/beta/read', 'resnet_model/batch_normalization_10/moving_mean/read', 'resnet_model/batch_normalization_10/moving_variance/read', 'resnet_model/conv2d_12/kernel/read', 'resnet_model/conv2d_13/kernel/read', 'resnet_model/batch_normalization_11/gamma/read', 'resnet_model/batch_normalization_11/beta/read', 'resnet_model/batch_normalization_11/moving_mean/read', 'resnet_model/batch_normalization_11/moving_variance/read', 'resnet_model/conv2d_14/kernel/read', 'resnet_model/batch_normalization_12/gamma/read', 'resnet_model/batch_normalization_12/beta/read', 'resnet_model/batch_normalization_12/moving_mean/read', 'resnet_model/batch_normalization_12/moving_variance/read', 'resnet_model/conv2d_15/kernel/read', 'resnet_model/batch_normalization_13/gamma/read', 'resnet_model/batch_normalization_13/beta/read', 'resnet_model/batch_normalization_13/moving_mean/read', 'resnet_model/batch_normalization_13/moving_variance/read', 'resnet_model/conv2d_16/kernel/read', 'resnet_model/batch_normalization_14/gamma/read', 'resnet_model/batch_normalization_14/beta/read', 'resnet_model/batch_normalization_14/moving_mean/read', 'resnet_model/batch_normalization_14/moving_variance/read', 'resnet_model/conv2d_17/kernel/read', 'resnet_model/batch_normalization_15/gamma/read', 'resnet_model/batch_normalization_15/beta/read', 'resnet_model/batch_normalization_15/moving_mean/read', 'resnet_model/batch_normalization_15/moving_variance/read', 'resnet_model/conv2d_18/kernel/read', 'resnet_model/batch_normalization_16/gamma/read', 'resnet_model/batch_normalization_16/beta/read', 'resnet_model/batch_normalization_16/moving_mean/read', 'resnet_model/batch_normalization_16/moving_variance/read', 'resnet_model/conv2d_19/kernel/read', 'resnet_model/batch_normalization_17/gamma/read', 'resnet_model/batch_normalization_17/beta/read', 'resnet_model/batch_normalization_17/moving_mean/read', 'resnet_model/batch_normalization_17/moving_variance/read', 'resnet_model/conv2d_20/kernel/read', 'resnet_model/batch_normalization_18/gamma/read', 'resnet_model/batch_normalization_18/beta/read', 'resnet_model/batch_normalization_18/moving_mean/read', 'resnet_model/batch_normalization_18/moving_variance/read', 'resnet_model/conv2d_21/kernel/read', 'resnet_model/batch_normalization_19/gamma/read', 'resnet_model/batch_normalization_19/beta/read', 'resnet_model/batch_normalization_19/moving_mean/read', 'resnet_model/batch_normalization_19/moving_variance/read', 'resnet_model/conv2d_22/kernel/read', 'resnet_model/block_layer2', 'resnet_model/batch_normalization_20/gamma/read', 'resnet_model/batch_normalization_20/beta/read', 'resnet_model/batch_normalization_20/moving_mean/read', 'resnet_model/batch_normalization_20/moving_variance/read', 'resnet_model/conv2d_23/kernel/read', 'resnet_model/conv2d_24/kernel/read', 'resnet_model/batch_normalization_21/gamma/read', 'resnet_model/batch_normalization_21/beta/read', 'resnet_model/batch_normalization_21/moving_mean/read', 'resnet_model/batch_normalization_21/moving_variance/read', 'resnet_model/conv2d_25/kernel/read', 'resnet_model/batch_normalization_22/gamma/read', 'resnet_model/batch_normalization_22/beta/read', 'resnet_model/batch_normalization_22/moving_mean/read', 'resnet_model/batch_normalization_22/moving_variance/read', 'resnet_model/conv2d_26/kernel/read', 'resnet_model/batch_normalization_23/gamma/read', 'resnet_model/batch_normalization_23/beta/read', 'resnet_model/batch_normalization_23/moving_mean/read', 'resnet_model/batch_normalization_23/moving_variance/read', 'resnet_model/conv2d_27/kernel/read', 'resnet_model/batch_normalization_24/gamma/read', 'resnet_model/batch_normalization_24/beta/read', 'resnet_model/batch_normalization_24/moving_mean/read', 'resnet_model/batch_normalization_24/moving_variance/read', 'resnet_model/conv2d_28/kernel/read', 'resnet_model/batch_normalization_25/gamma/read', 'resnet_model/batch_normalization_25/beta/read', 'resnet_model/batch_normalization_25/moving_mean/read', 'resnet_model/batch_normalization_25/moving_variance/read', 'resnet_model/conv2d_29/kernel/read', 'resnet_model/batch_normalization_26/gamma/read', 'resnet_model/batch_normalization_26/beta/read', 'resnet_model/batch_normalization_26/moving_mean/read', 'resnet_model/batch_normalization_26/moving_variance/read', 'resnet_model/conv2d_30/kernel/read', 'resnet_model/batch_normalization_27/gamma/read', 'resnet_model/batch_normalization_27/beta/read', 'resnet_model/batch_normalization_27/moving_mean/read', 'resnet_model/batch_normalization_27/moving_variance/read', 'resnet_model/conv2d_31/kernel/read', 'resnet_model/batch_normalization_28/gamma/read', 'resnet_model/batch_normalization_28/beta/read', 'resnet_model/batch_normalization_28/moving_mean/read', 'resnet_model/batch_normalization_28/moving_variance/read', 'resnet_model/conv2d_32/kernel/read', 'resnet_model/batch_normalization_29/gamma/read', 'resnet_model/batch_normalization_29/beta/read', 'resnet_model/batch_normalization_29/moving_mean/read', 'resnet_model/batch_normalization_29/moving_variance/read', 'resnet_model/conv2d_33/kernel/read', 'resnet_model/block_layer3', 'resnet_model/batch_normalization_30/gamma/read', 'resnet_model/batch_normalization_30/beta/read', 'resnet_model/batch_normalization_30/moving_mean/read', 'resnet_model/batch_normalization_30/moving_variance/read', 'resnet_model/final_reduce_mean', 'resnet_model/dense/kernel/read', 'resnet_model/dense/bias/read', 'resnet_model/final_dense']\n"
     ]
    }
   ],
   "source": [
    "freezed_filepath=os.path.join(saved_model_dir,'freezed_model.pb')\n",
    "describe_graph(get_graph_def_from_file(freezed_filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Optimise the freezed_model.pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimise GraphDef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_graph(model_dir, graph_filename, transforms):\n",
    "    \n",
    "    from tensorflow.tools.graph_transforms import TransformGraph\n",
    "    \n",
    "    input_names = []\n",
    "#    output_names = ['head/predictions/ExpandDims']\n",
    "    output_names = ['strided_slice']\n",
    "    \n",
    "    graph_def = get_graph_def_from_file(os.path.join(model_dir, graph_filename))\n",
    "    optimised_graph_def = TransformGraph(graph_def, \n",
    "                                         input_names,\n",
    "                                         output_names,\n",
    "                                         transforms \n",
    "                                        )\n",
    "    tf.train.write_graph(optimised_graph_def,\n",
    "                        logdir=model_dir,\n",
    "                        as_text=False,\n",
    "                        name='optimised_model.pb')\n",
    "    \n",
    "    print (\"Freezed graph optimised!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\\resnet\\dnn\\export\\1557163393\\freezed_model.pb\n",
      "\n",
      "Freezed graph optimised!\n"
     ]
    }
   ],
   "source": [
    "transforms = [\n",
    "    'remove_nodes(op=Identity)', \n",
    "    'fold_constants(ignore_errors=true)',\n",
    "    'fold_batch_norms',\n",
    "#    'fuse_resize_pad_and_conv',\n",
    "#    'quantize_weights',\n",
    "#    'quantize_nodes',\n",
    "    'merge_duplicate_nodes',\n",
    "    'strip_unused_nodes', \n",
    "    'sort_by_execution_order'\n",
    "]\n",
    "\n",
    "optimize_graph(saved_model_dir, 'freezed_model.pb', transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/mnist/cnn_classifier/export/1556574193\n",
      "freezed_model.pb\n",
      "optimised_model.pb\n",
      "saved_model.pb\n",
      "variables\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "saved_models_base=models/mnist/cnn_classifier/export/\n",
    "saved_model_dir=${saved_models_base}$(ls ${saved_models_base} | tail -n 1)\n",
    "echo ${saved_model_dir}\n",
    "ls ${saved_model_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Describe the Optimised Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\\resnet\\dnn\\export\\1557163393\\optimised_model.pb\n",
      "\n",
      "Input Feature Nodes: ['image']\n",
      "\n",
      "Unused Nodes: []\n",
      "\n",
      "Output Nodes: []\n",
      "\n",
      "Quanitization Nodes: []\n",
      "\n",
      "Constant Count: 168\n",
      "\n",
      "Variable Count: 0\n",
      "\n",
      "Identity Count: 0\n",
      "\n",
      "Total nodes: 291\n",
      "\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "optimised_filepath=os.path.join(saved_model_dir,'optimised_model.pb')\n",
    "describe_graph(get_graph_def_from_file(optimised_filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Convert Optimised graph (GraphDef) to SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_graph_def_to_saved_model(graph_filepath):\n",
    "\n",
    "    from tensorflow.python import ops\n",
    "    export_dir=os.path.join(saved_model_dir,'optimised')\n",
    "\n",
    "    if tf.gfile.Exists(export_dir):\n",
    "        tf.gfile.DeleteRecursively(export_dir)\n",
    "\n",
    "    graph_def = get_graph_def_from_file(graph_filepath)\n",
    "    \n",
    "    with tf.Session(graph=tf.Graph()) as session:\n",
    "        tf.import_graph_def(graph_def, name=\"\")\n",
    "        tf.saved_model.simple_save(session,\n",
    "                export_dir,\n",
    "                inputs={\n",
    "                    node.name: session.graph.get_tensor_by_name(\"{}:0\".format(node.name)) \n",
    "                    for node in graph_def.node if node.op=='Placeholder'},\n",
    "                outputs={\n",
    "                    \"class_ids\": session.graph.get_tensor_by_name(\"strided_slice:0\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        print (\"Optimised graph converted to SavedModel!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\\resnet\\dnn\\export\\1557163393\\optimised_model.pb\n",
      "\n",
      "Optimised graph converted to SavedModel!\n"
     ]
    }
   ],
   "source": [
    "optimised_filepath=os.path.join(saved_model_dir,'optimised_model.pb')\n",
    "convert_graph_def_to_saved_model(optimised_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimised SavedModel Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\\resnet\\dnn\\export\\1557163393\\optimised\n",
      "\n",
      "Model size: 1885.037 KB\n",
      "Variables size: 0.0 KB\n",
      "Total Size: 1885.037 KB\n"
     ]
    }
   ],
   "source": [
    "optimised_saved_model_dir = os.path.join(saved_model_dir,'optimised') \n",
    "get_size(optimised_saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved_model.pb\n",
      "variables\n",
      "\r\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\r\n",
      "\r\n",
      "signature_def['serving_default']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "    inputs['image'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 32, 32, 3)\r\n",
      "        name: image:0\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['class_ids'] tensor_info:\r\n",
      "        dtype: DT_INT64\r\n",
      "        shape: (-1, 1)\r\n",
      "        name: strided_slice:0\r\n",
      "  Method name is: tensorflow/serving/predict\r\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "saved_models_base=models/resnet/dnn/export/\n",
    "saved_model_dir=${saved_models_base}$(ls ${saved_models_base} | tail -n 1)/optimised\n",
    "ls ${saved_model_dir}\n",
    "saved_model_cli show --dir ${saved_model_dir} --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Prediction with the Optimised SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\\resnet\\dnn\\export\\1557163393\\optimised\n",
      "\n",
      "Model loading time: 0.088734 seconds\n",
      "\n",
      "Inference elapsed time: 737.303699 seconds\n",
      "\n",
      "Prediction produced for 300 instances batch, repeated 100 times\n",
      "Average latency per batch: 7.37303699 seconds\n",
      "\n",
      "Prediction output for the last instance:\n",
      "class_ids: [9]\n"
     ]
    }
   ],
   "source": [
    "optimised_saved_model_dir = os.path.join(saved_model_dir,'optimised') \n",
    "print(optimised_saved_model_dir)\n",
    "inference_test(saved_model_dir=optimised_saved_model_dir, signature='serving_default', input_name='image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud ML Engine Deployment and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'steven-wang-playground'\n",
    "BUCKET = 'steven-gcs-cloudml'\n",
    "REGION = 'europe-west1'\n",
    "MODEL_NAME = 'mnist_classifier'\n",
    "\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['MODEL_NAME'] = MODEL_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Upload the model artefacts to Google Cloud Storage bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "gsutil -m rm -r gs://${BUCKET}/tf-model-optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "saved_models_base=models/mnist/cnn_classifier/export/\n",
    "saved_model_dir=${saved_models_base}$(ls ${saved_models_base} | tail -n 1)\n",
    "\n",
    "echo ${saved_model_dir}\n",
    "\n",
    "gsutil -m cp -r ${saved_model_dir} gs://${BUCKET}/tf-model-optimisation/original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "saved_models_base=models/mnist/cnn_classifier/export/\n",
    "saved_model_dir=${saved_models_base}$(ls ${saved_models_base} | tail -n 1)/optimised\n",
    "\n",
    "echo ${saved_model_dir}\n",
    "\n",
    "gsutil -m cp -r ${saved_model_dir} gs://${BUCKET}/tf-model-optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Deploy models to Cloud ML Engine\n",
    "\n",
    "Don't forget to delete the model and the model version if they were previously deployed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "echo ${MODEL_NAME}\n",
    "\n",
    "gcloud ml-engine models create ${MODEL_NAME} --regions=${REGION}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Version: v_org** is the original SavedModel (before optimisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "MODEL_VERSION='v_org'\n",
    "MODEL_ORIGIN=gs://${BUCKET}/tf-model-optimisation/original\n",
    "\n",
    "gcloud ml-engine versions create ${MODEL_VERSION}\\\n",
    "            --model=${MODEL_NAME} \\\n",
    "            --origin=${MODEL_ORIGIN} \\\n",
    "            --runtime-version=1.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Version: v_opt** is the optimised SavedModel (after optimisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "MODEL_VERSION='v_opt'\n",
    "MODEL_ORIGIN=gs://${BUCKET}/tf-model-optimisation/optimised\n",
    "\n",
    "gcloud ml-engine versions create ${MODEL_VERSION}\\\n",
    "            --model=${MODEL_NAME} \\\n",
    "            --origin=${MODEL_ORIGIN} \\\n",
    "            --runtime-version=1.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cloud ML Engine online predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "api = discovery.build(\n",
    "    'ml', 'v1', \n",
    "    credentials=credentials, \n",
    "    discoveryServiceUrl='https://storage.googleapis.com/cloud-ml/discovery/ml_v1_discovery.json'\n",
    ")\n",
    "\n",
    "    \n",
    "def predict(version, instances):\n",
    "\n",
    "    request_data = {'instances': instances}\n",
    "\n",
    "    model_url = 'projects/{}/models/{}/versions/{}'.format(PROJECT, MODEL_NAME, version)\n",
    "    response = api.projects().predict(body=request_data, name=model_url).execute()\n",
    "\n",
    "    class_ids = None\n",
    "    \n",
    "    try:\n",
    "        class_ids = [item[\"class_ids\"] for item in response[\"predictions\"]]\n",
    "    except:\n",
    "        print response\n",
    "    \n",
    "    return class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_cmle(version, batch=100, repeat=10):\n",
    "    \n",
    "    instances = [\n",
    "            {'input_image': [float(i) for i in list(eval_data[img])] }\n",
    "        for img in range(batch)\n",
    "    ]\n",
    "\n",
    "    #warmup request\n",
    "    predict(version, instances[0])\n",
    "    print 'Warm up request performed!'\n",
    "    print 'Timer started...'\n",
    "    print ''\n",
    "    \n",
    "    time_start = datetime.utcnow() \n",
    "    output = None\n",
    "    \n",
    "    for i in range(repeat):\n",
    "        output = predict(version, instances)\n",
    "    \n",
    "    time_end = datetime.utcnow() \n",
    "\n",
    "    time_elapsed_sec = (time_end - time_start).total_seconds()\n",
    "    \n",
    "    print \"Inference elapsed time: {} seconds\".format(time_elapsed_sec)\n",
    "    print \"\"\n",
    "    \n",
    "    print \"Prediction produced for {} instances batch, repeated {} times\".format(len(output), repeat)\n",
    "    print \"Average latency per batch: {} seconds\".format(time_elapsed_sec/repeat)\n",
    "    print \"\"\n",
    "    \n",
    "    print \"Prediction output for the last instance: {}\".format(output[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version='v_org'\n",
    "inference_cmle(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version='v_opt'\n",
    "inference_cmle(version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Happy serving!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
